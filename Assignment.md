# Практическое задание 1: Классификация токсичных комментариев

## Общая идея

Необходимо разработать решение на языке **Python**, которое классифицирует комментарии к исходному коду на **токсичные** и **не токсичные**.  
Задание состоит из двух этапов: подготовка данных и обучение моделей (классических и BERT-подобных).

---

## 1. Подготовка данных

**Цель:** очистить и подготовить размеченные рецензии из репозитория [ToxiCR](https://github.com/WSU-SEAL/ToxiCR/tree/master).

**Основные шаги:**
- Удалить пропуски и дубликаты.
- Очистить тексты:
  - удалить ссылки и спецсимволы (`&, #, ^, *` и др.);
  - раскрыть сокращения (`doesn’t → does not`, `we’re → we are`);
  - исправить повторяющиеся символы (`duumbbbb → dumb`);
  - нормализовать испорченные ругательства (словарь в ToxiCR);
  - при необходимости добавить собственные методы очистки.
- Сохранить подготовленные данные для обучения моделей.

---

## 2. Обучение моделей

### Классические методы (scikit-learn)
- Преобразовать тексты в числовой вид с помощью **CountVectorizer** или **TfidfVectorizer**.  
- Обучить модели **Logistic Regression** и/или **Random Forest**.  
- Провести оценку через **10-кратную кросс-валидацию (KFold)**.  
- Построить **confusion matrix** и проанализировать результаты.  
- Провести эксперименты с гиперпараметрами и методами извлечения признаков для повышения качества.

### Модели на основе трансформеров (HuggingFace Transformers)
- Использовать токенизатор **RoBERTa** или **CodeBERT**.  
- Инициализировать `AutoModelForSequenceClassification` и `Trainer`, задать параметры обучения (эпохи, батч, learning rate).  
- Реализовать вычисление метрик `accuracy`, `precision`, `recall`, `f1-score` через `compute_metrics`.  
- Сравнить результаты всех моделей и оформить краткий отчет (1–2 страницы) с выводами.

---

## 3. Оценка и баллы

- Курс оценивается по **10-балльной шкале**.  
- Практические задания дают около **70%** итоговой оценки, остальное — **устный экзамен**.  
- За это задание можно получить максимум **2 балла**:
  - 1 балл — за классические модели;
  - 1 балл — за BERT-модели (RoBERTa или CodeBERT).
- Целевой ориентир: **F1-score ≈ 0.7** при использовании классических подходов.
- Второе задание — до **3 баллов**, третье — до **2–3 баллов** (уточняется по ходу курса).

---

## 4. Формат и сдача

- Выполнять можно в виде модулей Python, Jupyter Notebook или в Google Colab.  
- Репозиторий или Colab с решением необходимо отправить по почте **ksorokin@ispras.ru**  
  с темой письма: **"Первое практическое задание"**, указав имя автора.  
- Использовать виртуальное окружение, зависимости зафиксированы в шаблоне.  
- Срок выполнения — **2 недели** с момента выдачи.  
- При необходимости может потребоваться короткое устное объяснение решения.

---